## Run time python2.7.13


### performance test
`
Class 2 Multiple Layer Perceptron (MLP) Example
Test Accuracy: 0.9326599326599325

`

### library
`
Class 2 sklearn MLP Example
Iteration 1, loss = 2.37029905
Iteration 2, loss = 2.26380956
Iteration 3, loss = 2.16220843
Iteration 4, loss = 2.08024079
Iteration 5, loss = 2.00289872
Iteration 6, loss = 1.93227071
Iteration 7, loss = 1.86649838
Iteration 8, loss = 1.80478412
Iteration 9, loss = 1.74669235
Iteration 10, loss = 1.69239376
Iteration 11, loss = 1.63971269
Iteration 12, loss = 1.59056035
Iteration 13, loss = 1.54346583
Iteration 14, loss = 1.49821128
Iteration 15, loss = 1.45543655
Iteration 16, loss = 1.41406274
Iteration 17, loss = 1.37469218
Iteration 18, loss = 1.33682624
Iteration 19, loss = 1.30040059
Iteration 20, loss = 1.26553731
Iteration 21, loss = 1.23206559
Iteration 22, loss = 1.19991211
Iteration 23, loss = 1.16906297
Iteration 24, loss = 1.13955396
Iteration 25, loss = 1.11099869
Iteration 26, loss = 1.08385392
Iteration 27, loss = 1.05739599
Iteration 28, loss = 1.03221186
Iteration 29, loss = 1.00792130
Iteration 30, loss = 0.98444112
Iteration 31, loss = 0.96194694
Iteration 32, loss = 0.94010942
Iteration 33, loss = 0.91920695
Iteration 34, loss = 0.89902747
Iteration 35, loss = 0.87948251
Iteration 36, loss = 0.86051630
Iteration 37, loss = 0.84242934
Iteration 38, loss = 0.82482081
Iteration 39, loss = 0.80799864
Iteration 40, loss = 0.79165789
Iteration 41, loss = 0.77579051
Iteration 42, loss = 0.76040643
Iteration 43, loss = 0.74560284
Iteration 44, loss = 0.73147907
Iteration 45, loss = 0.71756541
Iteration 46, loss = 0.70417056
Iteration 47, loss = 0.69123037
Iteration 48, loss = 0.67863234
Iteration 49, loss = 0.66635860
Iteration 50, loss = 0.65465954
Iteration 51, loss = 0.64322712
Iteration 52, loss = 0.63220574
Iteration 53, loss = 0.62148490
Iteration 54, loss = 0.61093957
Iteration 55, loss = 0.60087111
Iteration 56, loss = 0.59098984
Iteration 57, loss = 0.58154056
Iteration 58, loss = 0.57224004
Iteration 59, loss = 0.56326154
Iteration 60, loss = 0.55449202
Iteration 61, loss = 0.54607373
Iteration 62, loss = 0.53783662
Iteration 63, loss = 0.52980736
Iteration 64, loss = 0.52208395
Iteration 65, loss = 0.51440387
Iteration 66, loss = 0.50709418
Iteration 67, loss = 0.49990385
Iteration 68, loss = 0.49283375
Iteration 69, loss = 0.48609233
Iteration 70, loss = 0.47943101
Iteration 71, loss = 0.47303383
Iteration 72, loss = 0.46662706
Iteration 73, loss = 0.46046870
Iteration 74, loss = 0.45454249
Iteration 75, loss = 0.44858127
Iteration 76, loss = 0.44297829
Iteration 77, loss = 0.43737478
Iteration 78, loss = 0.43192624
Iteration 79, loss = 0.42670403
Iteration 80, loss = 0.42158924
Iteration 81, loss = 0.41637447
Iteration 82, loss = 0.41146769
Iteration 83, loss = 0.40665947
Iteration 84, loss = 0.40187389
Iteration 85, loss = 0.39730819
Iteration 86, loss = 0.39270380
Iteration 87, loss = 0.38836182
Iteration 88, loss = 0.38403872
Iteration 89, loss = 0.37975411
Iteration 90, loss = 0.37564117
Iteration 91, loss = 0.37162489
Iteration 92, loss = 0.36765050
Iteration 93, loss = 0.36387182
Iteration 94, loss = 0.35998180
Iteration 95, loss = 0.35632778
Iteration 96, loss = 0.35263144
Iteration 97, loss = 0.34911045
Iteration 98, loss = 0.34558233
Iteration 99, loss = 0.34220075
/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.
  % (), ConvergenceWarning)
Iteration 100, loss = 0.33882596
Training set score: 0.959333
Test set score: 0.878788

`